---
title: "Data Evaluation for Quality Assurance and Understanding in Graphs"
subtitle: "Stephen Howe"
output: html_notebook
---

This notebook was run on `r Sys.Date()`

# Notebook Setup
## Configuration
```{r packages, warning=FALSE, message=FALSE}
library(aws.s3)
library(arrow)
library(duckdb)
library(dplyr)
library(ggplot2)
library(tidyr)
library(plotly)
library(tictoc)
```

##  Create Connections to Datasets
This code establishes a connection to the .parquet files in SAND_DS S3 as arrow datasets and then again as duckDB tables.
```{r datasets}
# arrow datasets of nodes
da <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/nodes/distinctauthor")
inst <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/nodes/linked_institutions/")
art <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/nodes/projected_article/")

au_docs <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/output/phyeng/json/graph/nodes/r4r_projection_authors",
  format = "json") # json projection

# arrow datasets of edges
aff <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/edges/AFFILIATION/")
contr <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/edges/CONTRIBUTION")
topics <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/edges/TOPIC_OF_INTEREST")
collab <- open_dataset(
  "s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/edges/COLLABORATOR")

# register duckdb tables
con <- dbConnect(duckdb::duckdb())
duckdb_register_arrow(con, "distinctAuthor", da)
duckdb_register_arrow(con, "institutions", inst)
duckdb_register_arrow(con, "articles", art)
duckdb_register_arrow(con, "affiliated_to", aff)
duckdb_register_arrow(con, "contribution", contr)
duckdb_register_arrow(con, "topics_of_interest", topics)
duckdb_register_arrow(con, "collaborators", collab)
duckdb_register_arrow(con, "author_docs", au_docs)
```

TODO: Examine .json files in S3 to see how they are structured

## Describe Tables
```{r}
# describe
dbGetQuery(con, "DESCRIBE table distinctAuthor")
dbGetQuery(con, "DESCRIBE table institutions")
dbGetQuery(con, "DESCRIBE table articles")
dbGetQuery(con, "DESCRIBE table affiliated_to")
dbGetQuery(con, "DESCRIBE table contribution")
dbGetQuery(con, "DESCRIBE table topics_of_interest")
dbGetQuery(con, "DESCRIBE table collaborators")
dbGetQuery(con, "DESCRIBE table author_docs")
```

# Areas of Evaluation
## Descriptive Statistics / Data Profiling
Any evaluation of data for quality and understanding should start with the calculation of descriptive and aggregate statistics and the creation of a comprehensive profile of the dataset. These statistics provide foundational information about the dataset itself that can work as a baseline in the other areas of evaluation. Calculated over time, descriptive and aggregate statistics are useful for understanding how the shape of the data is changing and trending.

* Descriptive Statistics
* Count of node by type
* Count of edges by type
* Description of datatype of node attributes
* Description of datatype of edge attributes
* Distribution (five number summary) of numeric attributes

# Speed Test
```{r, eval=FALSE}
# # arrow + json
# tic()
# au_docs |> count(persistent_identifier) |> collect()
# toc()

# arrow + parquet
tic()
da |> count() |> collect()
toc()

# arrow + duckdb + json
# tic()
# dbGetQuery(
#   con,
#   "SELECT count(persistent_identifier) FROM author_doc"
# )
# toc()

# arrow + duckdb + parquet
tic()
dbGetQuery(
  con,
  "SELECT count(*) FROM distinctAuthor"
)
toc()
```

### Counts of Nodes
```{r}
count_da <- dbGetQuery(con, "SELECT count(*) FROM distinctAuthor")
count_art <- dbGetQuery(con, "SELECT count(*) FROM articles")
count_inst <- dbGetQuery(con, "SELECT count(*) FROM institutions")
tibble(
  node = c("distinctAuthors", "articles", "institutions"),
  count = c(count_da[[1]], count_art[[1]], count_inst[[1]])
)
```

### Distributions of Key Node Properties - distinctAuthor
```{r}
# forename
dist_forename <- dbGetQuery(
  con,
  "SELECT
    'forename' as property,
    MIN(LENGTH(da.forename)) as min,
    QUANTILE_CONT(LENGTH(da.forename), 0.25) as p25,
    MEDIAN(LENGTH(da.forename)) as med,
    QUANTILE_CONT(LENGTH(da.forename), 0.75) as p75,
    QUANTILE_CONT(LENGTH(da.forename), 0.9) as p90,
    QUANTILE_CONT(LENGTH(da.forename), 0.95) as p95,
    QUANTILE_CONT(LENGTH(da.forename), 0.99) as p99,
    QUANTILE_CONT(LENGTH(da.forename), 0.999) as p999,
    QUANTILE_CONT(LENGTH(da.forename), 0.9999) as p9999,
    MAX(LENGTH(da.forename)) as max
  FROM distinctAuthor da"
)

# occurences
dist_occurences <- dbGetQuery(
  con,
  "SELECT
    'occurences' as property,
    MIN(da.occurrences) as min,
    QUANTILE_CONT(da.occurrences, 0.25) as p25,
    MEDIAN(da.occurrences) as med,
    QUANTILE_CONT(da.occurrences, 0.75) as p75,
    QUANTILE_CONT(da.occurrences, 0.9) as p90,
    QUANTILE_CONT(da.occurrences, 0.95) as p95,
    QUANTILE_CONT(da.occurrences, 0.99) as p99,
    QUANTILE_CONT(da.occurrences, 0.999) as p999,
    QUANTILE_CONT(da.occurrences, 0.9999) as p9999,
    MAX(da.occurrences) as max
  FROM distinctAuthor da"
)

# name_variants
dist_namevariants <- dbGetQuery(
  con,
  "SELECT
    'name_variants' as property,
    MIN(LENGTH(da.name_variants)) as min,
    QUANTILE_CONT(LENGTH(da.name_variants), 0.25) as p25,
    MEDIAN(LENGTH(da.name_variants)) as med,
    QUANTILE_CONT(LENGTH(da.name_variants), 0.75) as p75,
    QUANTILE_CONT(LENGTH(da.name_variants), 0.9) as p90,
    QUANTILE_CONT(LENGTH(da.name_variants), 0.95) as p95,
    QUANTILE_CONT(LENGTH(da.name_variants), 0.99) as p99,
    QUANTILE_CONT(LENGTH(da.name_variants), 0.999) as p999,
    QUANTILE_CONT(LENGTH(da.name_variants), 0.9999) as p9999,
    MAX(LENGTH(da.name_variants)) as max
  FROM distinctAuthor da"
)

# degree_of_belief
dist_dob <- dbGetQuery(
  con,
  "SELECT
    'degree_of_belief' as property,
    MIN(da.degree_of_belief) as min,
    QUANTILE_CONT(da.degree_of_belief, 0.25) as p25,
    MEDIAN(da.degree_of_belief) as med,
    QUANTILE_CONT(da.degree_of_belief, 0.75) as p75,
    QUANTILE_CONT(da.degree_of_belief, 0.9) as p90,
    QUANTILE_CONT(da.degree_of_belief, 0.95) as p95,
    QUANTILE_CONT(da.degree_of_belief, 0.99) as p99,
    QUANTILE_CONT(da.degree_of_belief, 0.999) as p999,
    QUANTILE_CONT(da.degree_of_belief, 0.9999) as p9999,
    MAX(da.degree_of_belief) as max
  FROM distinctAuthor da"
)

# orcid
dist_orcid <- dbGetQuery(
  con,
  "SELECT
    'orcid' as property,
    MIN(LENGTH(da.orcid)) as min,
    QUANTILE_CONT(LENGTH(da.orcid), 0.25) as p25,
    MEDIAN(LENGTH(da.orcid)) as med,
    QUANTILE_CONT(LENGTH(da.orcid), 0.75) as p75,
    QUANTILE_CONT(LENGTH(da.orcid), 0.9) as p90,
    QUANTILE_CONT(LENGTH(da.orcid), 0.95) as p95,
    QUANTILE_CONT(LENGTH(da.orcid), 0.99) as p99,
    QUANTILE_CONT(LENGTH(da.orcid), 0.999) as p999,
    QUANTILE_CONT(LENGTH(da.orcid), 0.9999) as p9999,
    MAX(LENGTH(da.orcid)) as max
  FROM distinctAuthor da"
)

# articles_as_single_author
dist_articles_as_single_author <- dbGetQuery(
  con,
  "SELECT
    'articles_as_single_author' as property,
    MIN(da.articles_as_single_author) as min,
    QUANTILE_CONT(da.articles_as_single_author, 0.25) as p25,
    MEDIAN(da.articles_as_single_author) as med,
    QUANTILE_CONT(da.articles_as_single_author, 0.75) as p75,
    QUANTILE_CONT(da.articles_as_single_author, 0.9) as p90,
    QUANTILE_CONT(da.articles_as_single_author, 0.95) as p95,
    QUANTILE_CONT(da.articles_as_single_author, 0.99) as p99,
    QUANTILE_CONT(da.articles_as_single_author, 0.999) as p999,
    QUANTILE_CONT(da.articles_as_single_author, 0.9999) as p9999,
    MAX(da.articles_as_single_author) as max
  FROM distinctAuthor da"
)

# collaborators_count
dist_collaborators_count <- dbGetQuery(
  con,
  "SELECT
    'collaborators_count' as property,
    MIN(da.collaborators_count) as min,
    QUANTILE_CONT(da.collaborators_count, 0.25) as p25,
    MEDIAN(da.collaborators_count) as med,
    QUANTILE_CONT(da.collaborators_count, 0.75) as p75,
    QUANTILE_CONT(da.collaborators_count, 0.9) as p90,
    QUANTILE_CONT(da.collaborators_count, 0.95) as p95,
    QUANTILE_CONT(da.collaborators_count, 0.99) as p99,
    QUANTILE_CONT(da.collaborators_count, 0.999) as p999,
    QUANTILE_CONT(da.collaborators_count, 0.9999) as p9999,
    MAX(da.collaborators_count) as max
  FROM distinctAuthor da"
)

# topics
dist_topics <- dbGetQuery(
  con,
  "SELECT
    'topics' as property,
    MIN(LENGTH(da.topics)) as min,
    QUANTILE_CONT(LENGTH(da.topics), 0.25) as p25,
    MEDIAN(LENGTH(da.topics)) as med,
    QUANTILE_CONT(LENGTH(da.topics), 0.75) as p75,
    QUANTILE_CONT(LENGTH(da.topics), 0.9) as p90,
    QUANTILE_CONT(LENGTH(da.topics), 0.95) as p95,
    QUANTILE_CONT(LENGTH(da.topics), 0.99) as p99,
    QUANTILE_CONT(LENGTH(da.topics), 0.999) as p999,
    QUANTILE_CONT(LENGTH(da.topics), 0.9999) as p9999,
    MAX(LENGTH(da.topics)) as max
  FROM distinctAuthor da"
)

# authorship_period
dist_author_period_years <- dbGetQuery(
  con,
  "SELECT
  'authorship_period_years' AS property,
  MIN(years) AS min,
  QUANTILE_CONT(years, 0.25) AS p25,
  MEDIAN(years) AS med,
  QUANTILE_CONT(years, 0.75) AS p75,
  QUANTILE_CONT(years, 0.9) AS p90,
  QUANTILE_CONT(years, 0.95) AS p95,
  QUANTILE_CONT(years, 0.99) AS p99,
  QUANTILE_CONT(years, 0.999) AS p999,
  QUANTILE_CONT(years, 0.9999) AS p9999,
  MAX(years) AS max
FROM (
  SELECT
    ROUND((authorship_period[2] - authorship_period[1])::DOUBLE / 365.25, 2) AS years
  FROM distinctAuthor
  WHERE authorship_period IS NOT NULL
    AND array_length(authorship_period) = 2
) t;"
)

rbind(
  dist_forename,
  dist_occurences,
  dist_namevariants,
  dist_dob,
  dist_orcid,
  dist_articles_as_single_author,
  dist_collaborators_count,
  dist_topics,
  dist_author_period_years
)
```

### Distributions of Key Node Properties - articles
```{r}
# pubdate_range
pubdate_range <- dbGetQuery(
  con,
  "SELECT
    'pubdate_range' as property,
    MIN(pub_date) as min,
    MAX(pub_date) as max
  FROM articles"
)

pubdate_range

# keywords
dist_art_keywords <- dbGetQuery(
  con,
  "SELECT
    'keywords' as property,
    MIN(LENGTH(art.keywords)) as min,
    QUANTILE_CONT(LENGTH(art.keywords), 0.25) as p25,
    MEDIAN(LENGTH(art.keywords)) as med,
    QUANTILE_CONT(LENGTH(art.keywords), 0.75) as p75,
    QUANTILE_CONT(LENGTH(art.keywords), 0.9) as p90,
    QUANTILE_CONT(LENGTH(art.keywords), 0.95) as p95,
    QUANTILE_CONT(LENGTH(art.keywords), 0.99) as p99,
    QUANTILE_CONT(LENGTH(art.keywords), 0.999) as p999,
    QUANTILE_CONT(LENGTH(art.keywords), 0.9999) as p9999,
    MAX(LENGTH(art.keywords)) as max
  FROM articles art"
)

# article topics
dist_art_topics <- dbGetQuery(
  con,
  "SELECT
    'topics' as property,
    MIN(LENGTH(art.topics)) as min,
    QUANTILE_CONT(LENGTH(art.topics), 0.25) as p25,
    MEDIAN(LENGTH(art.topics)) as med,
    QUANTILE_CONT(LENGTH(art.topics), 0.75) as p75,
    QUANTILE_CONT(LENGTH(art.topics), 0.9) as p90,
    QUANTILE_CONT(LENGTH(art.topics), 0.95) as p95,
    QUANTILE_CONT(LENGTH(art.topics), 0.99) as p99,
    QUANTILE_CONT(LENGTH(art.topics), 0.999) as p999,
    QUANTILE_CONT(LENGTH(art.topics), 0.9999) as p9999,
    MAX(LENGTH(art.topics)) as max
  FROM articles art"
)

rbind(
  dist_art_keywords,
  dist_art_topics
)
```

### Count of Edges
```{r}
count_aff <- dbGetQuery(con, "SELECT count(*) FROM affiliated_to")
count_contr <- dbGetQuery(con, "SELECT count(*) FROM contribution")
# count_topics <- dbGetQuery(con, "SELECT count(*) FROM topics_of_interest")
# count_collab <- dbGetQuery(con, "SELECT count(*) FROM collaborators") # long run time
tibble(
  edge = c("affiliated_to", "contributed_to"),
  count = c(count_aff[[1]], count_contr[[1]])
)
```




### CM1
% of distinctAuthors with at least one `contribution` edge.
```{r}
count_da <- dbGetQuery(
  con,
  "Select count(distinct id)
  from distinctAuthor"
)

count_contr_distinct <- dbGetQuery(
  con,
  "SELECT count(distinct source)
  from contribution"
)

count_contr_distinct$`count(DISTINCT source)` / count_da$`count(DISTINCT id)`
```

Ratio of contribution edges to occurrences
```{r}
count_occ <- dbGetQuery(
  con,
  "SELECT SUM(occurrences)
  FROM distinctAuthor"
)

count_contr <- dbGetQuery(
  con,
  "SELECT count(*)
  FROM contribution"
)

count_contr$`count_star()` / count_occ$`sum(occurrences)`
```

Comfirm against json docs
```{r, eval=FALSE}
count_da_json <- dbGetQuery(
  con,
  "SELECT count(persistent_identifier) from author_docs "
)

count_da == count_da_json
```

### CM2
% of distinctAuthors with at least one affiliation edge
```{r}
count_aff_distinct <- dbGetQuery(
  con,
  "SELECT count(distinct source)
  from affiliated_to"
)

count_aff_distinct$`count(DISTINCT source)` / count_da$`count(DISTINCT id)`
```

Count of distinctAuthors with no affiliation edge
```{r}
count_da$`count(DISTINCT id)` - count_aff_distinct$`count(DISTINCT source)`
```

### CM3
% of distinctAuthors with at least one TOPIC_OF_INTERST
```{r}
count_topics_distinct <- dbGetQuery(
  con,
  "SELECT count(distinct source)
  from topics_of_interest"
)

count_topics_distinct$`count(DISTINCT source)` / count_da$`count(DISTINCT id)`
```

From projected json documents
```{r}
count_topics_distinct_json <- au_docs |>
  select(persistent_identifier, concepts) |> 
  collect() |>
  unnest(concepts)

count_topics_distinct_json |>
  distinct(persistent_identifier) |>
  count()
```

### CM4
% of distinctAuthors with at least on collaborated_with edge
```{r}
count_collab_distinct <- dbGetQuery(
  con,
  "SELECT count(distinct source)
  FROM collaborators"
)

count_collab_distinct$`count(DISTINCT source)` / count_da$`count(DISTINCT id)`
```

Count of distinctAuthors with no collaborators
```{r}
count_da$`count(DISTINCT id)` - count_collab_distinct$`count(DISTINCT source)`
```

### CM5
% of distinctAuthors with forename >3 characters in length
```{r}
count_namelength_distinct <- dbGetQuery(
  con,
  "SELECT count(distinct id)
  FROM distinctAuthor
  WHERE length(forename) > 2"
)

count_namelength_distinct$`count(DISTINCT id)` / count_da$`count(DISTINCT id)`
```

Count of distinctAuthors with givenname <=3 characters in length
```{r}
count_da$`count(DISTINCT id)` - count_namelength_distinct$`count(DISTINCT id)`
```

Examples:
```{r}
dbGetQuery(
  con,
  "SELECT id, forename, lastname
  FROM distinctAuthor
  WHERE length(forename) < 3
  LIMIT 1000"
)

```

### AR-CM1
% of articles with a DOI
```{r}
count_article <- dbGetQuery(
  con,
  "SELECT count(*)
  FROM articles"
)

count_hasDOI <- dbGetQuery(
  con,
  "SELECT COUNT(*)
  FROM articles
  WHERE doi IS NOT NULL
  AND TRIM(doi) <> ''"
)

count_hasDOI$`count_star()` / count_article$`count_star()`
```

### AR-CM2
% of articles with a pub_date
```{r}
count_hasPubDate <- dbGetQuery(
  con,
  "SELECT count(*)
  FROM articles
  WHERE pub_date IS NOT NULL"
)

count_hasPubDate$`count_star()` / count_article$`count_star()`
```

## Fivenum Summaries and Thresholds
### What is the distribution of occurrences?
```{r}
dbGetQuery(con,
           "SELECT MIN(da.occurrences) as min,
           QUANTILE_CONT(da.occurrences, 0.25) as p25,
           MEDIAN(da.occurrences) as med,
           QUANTILE_CONT(da.occurrences, 0.75) as p75,
           QUANTILE_CONT(da.occurrences, 0.9) as p90,
           QUANTILE_CONT(da.occurrences, 0.95) as p95,
           QUANTILE_CONT(da.occurrences, 0.99) as p99,
           QUANTILE_CONT(da.occurrences, 0.999) as p999,
           QUANTILE_CONT(da.occurrences, 0.9999) as p9999,
           MAX(da.occurrences) as max
           FROM distinctAuthor da")
```

### What is the distribution of the number of collaborators
```{r}
dbGetQuery(con,
           "SELECT MIN(da.collaborators_count) as min,
           QUANTILE_CONT(da.collaborators_count, 0.25) as p25,
           MEDIAN(da.collaborators_count) as med,
           QUANTILE_CONT(da.collaborators_count, 0.75) as p75,
           QUANTILE_CONT(da.collaborators_count, 0.9) as p90,
           QUANTILE_CONT(da.collaborators_count, 0.95) as p95,
           QUANTILE_CONT(da.collaborators_count, 0.99) as p99,
           QUANTILE_CONT(da.collaborators_count, 0.999) as p999,
           QUANTILE_CONT(da.collaborators_count, 0.9999) as p9999,
           MAX(da.collaborators_count) as max
           FROM distinctAuthor da")
```
### What is the distribution of affiliations per author?
```{r}
affialtions_to_author <- aff |>
  group_by(source) |>
  summarise(count = n(),
            ) |>
  collect()

affialtions_to_author |>
  summarise(percentiles = c(0,.25,0.5,0.75,0.9,0.99,0.999,0.9999, 1.0),
            count_aff = quantile(count, c(0,.25,0.5,0.75,0.9,0.99,0.999,0.9999, 1.0)))
```







# Experiments and Scratch
```{r, eval=FALSE}
contr |>
  filter(source == "r4r:01JMF02071PWPPHT022S30NJQW") |>
  collect()


da_json <- open_dataset("s3://com-copyright-agpipeline-sandds/data/output/phyeng/json/graph/nodes/r4r_projection_authors/",
                        format = "json")
duckdb_register_arrow(con, "da_json", da_json)

test_1 <- dbGetQuery(
  con,
  "SELECT *
  FROM da_json
  WHERE persistent_identifier = 'r4r:01JMF02071PWPPHT022S30NJQW'"
)


top_topic <- open_dataset("s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/edges/TOP_TOPIC/")
top_topic |> count() |> collect()

topics |> count() |> collect()

field_of_study <- open_dataset("s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/edges/FIELD_OF_STUDY/")
field_of_study |> count() |> collect()


articles <- open_dataset("s3://com-copyright-agpipeline-sandds/data/internal/parquet/r4r/phyeng/graph/nodes/article/")
articles |> count() |> collect()
fugazi_2 <- articles |> head(10) |> collect()


au_docs <- open_dataset("s3://com-copyright-agpipeline-sandds/data/output/phyeng/json/graph/nodes/", format = "json")
duckdb_register_arrow(con, "author_doc", au_docs)
dbGetQuery(
  con,
  "SELECT *
  FROM author_doc
  WHERE persistent_identifier = 'r4r:01JMF02071PWPPHT022S30NJQW'"
)


fugazi_3 <- dbGetQuery(
  con,
  "SELECT da.id, count(c.id)
  FROM distinctAuthor da
  JOIN contribution c on da.id = c.source
  WHERE length(forename) > 2
  GROUP BY da.id
  "
)


aff |>
  group_by(source) |>
  summarise(count = n(),
            ) |>
  filter(count > 4) |>
  count() |>
  collect()
```

## Thresholds
## ORCID
```{r}
r4rid_orcid <- dbGetQuery(
  con,
  "SELECT id, occurrences, orcid
  FROM distinctAuthor
  WHERE LEN(orcid) > 1"
)

r4rid_orcid_unnest <- tibble(
  r4r_id = r4rid_orcid$id,
  occurrences = r4rid_orcid$occurrences,
  orcid = r4rid_orcid$orcid) |>
  unnest_longer(orcid) |>
  filter(orcid != "")

id_orc_occ <- r4rid_orcid_unnest |>
  group_by(r4r_id, occurrences) |>
  summarise(orc_count = n())

fivenum(id_orc_occ$orc_count)
quantile(id_orc_occ$orc_count, c(.9,.99,.999, .9999))
```
